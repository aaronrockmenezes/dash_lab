{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is an operating system? 1\n",
      "What is the OSI model? 2\n",
      "Who was Alan Turing? 3\n",
      "How do computer networks work? 4\n",
      "What is the Linux Kernel? 5\n",
      "What is a File system? 6\n",
      "What is Docker? 7\n",
      "What is a GPU and how is it different from a CPU? 8\n",
      "What are the layers of the OSI model? 9\n",
      "What is BeeGFS? 10\n",
      "What are the various components that comprise a computer? 11\n",
      "What is Federated Learning? 12\n"
     ]
    }
   ],
   "source": [
    "with open('./input.txt', \"r+\") as input_file:\n",
    "    for i, line in enumerate(input_file):\n",
    "        prompt = line.strip()\n",
    "        print(prompt, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'aaron', 'age': 25, 'name2': 'joe'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = {\n",
    "    'name':'aaron',\n",
    "    'age': 25\n",
    "}\n",
    "\n",
    "dictionary.update({'name2':'joe'})\n",
    "\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import time\n",
    "import os\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Provide relative path to input and output files\n",
    "input_file_path = \"./input.txt\"\n",
    "output_file_name = \"output.json\"\n",
    "\n",
    "# Model parameters\n",
    "MODEL = \"gemma2-9b-it\"\n",
    "TEMPERATURE = 0.2\n",
    "MAX_TOKENS = 64\n",
    "\n",
    "# Function to get chat completion\n",
    "def get_chat_completion(prompt:str, model:str=\"gemma2-9b-it\", temperature:float=0.2, max_tokens:int=64):\n",
    "    \"\"\"\n",
    "    Function to get chat completion from GROQ API\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prompt : str\n",
    "        User input prompt\n",
    "    model : str, optional\n",
    "        Model name, by default \"gemma2-9b-it\"\n",
    "    temperature : float, optional\n",
    "        Temperature parameter, by default 0.2\n",
    "    max_tokens : int, optional\n",
    "        Maximum tokens to generate, by default 64\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Chat completion message\n",
    "    \"\"\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who answers questions in brief, informative responses.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    return chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-f4a7d5ff-2ce5-4ce2-9b78-0fbf11a4f729', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Paris. \\n', role='assistant', function_call=None, tool_calls=None))], created=1724954386, model='gemma2-9b-it', object='chat.completion', system_fingerprint='fp_10c08bf97d', usage=CompletionUsage(completion_tokens=6, prompt_tokens=30, total_tokens=36, completion_time=0.010909091, prompt_time=0.000132179, queue_time=0.014112321, total_time=0.01104127), x_groq={'id': 'req_01j6fmp89efyjvbr2cnadrqpre'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = get_chat_completion(\"What is the capital of France?\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dash_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
